{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speed_predict.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viraatdas/Purdue_CompVis_Workshop/blob/11_testing/speed_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR3KB9wg6hD2",
        "colab_type": "code",
        "outputId": "25b64616-37ed-4ac7-f0e8-e00d3a89b2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"wus good\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wus good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLBdc5Nk7Q5h",
        "colab_type": "text"
      },
      "source": [
        "Import video files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp6CXi_M7X_o",
        "colab_type": "code",
        "outputId": "e3725e0d-065c-4587-d211-4db6ddb94073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0g_bHtb9SkX",
        "colab_type": "text"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEZ1WRGL9VBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHAYyhZ0I1x8",
        "colab_type": "text"
      },
      "source": [
        "Organize file paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvpxqGIeI4K4",
        "colab_type": "code",
        "outputId": "3c96dd0b-f9be-4f85-f8a6-aeadb87626c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "train_video = \"./drive/My Drive/speed_predict/train.mp4\"\n",
        "labels = \"./drive/My Drive/speed_predict/train.txt\"\n",
        "OUTPUT_PATH = \"./drive/My Drive/speed_predict/data_preprocessed/\"\n",
        "FRAME_RATE = 20\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "  os.mkdir(output_path)\n",
        "  print(f\"Directory {output_path} created\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9867bac8ce66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mFRAME_RATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Directory {output_path} created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3m-C0w3I4X2",
        "colab_type": "text"
      },
      "source": [
        "PreProcessor Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSd_lkW4I8K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreProcessor():\n",
        "  def __str__(self):\n",
        "    # indicate class description\n",
        "    return \"Pre-processor class\"\n",
        "  def grayscale(self, frame):\n",
        "    # converts frame to gray scale\n",
        "    return cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "  \n",
        "  def plot_training_speed(self, data):\n",
        "    # plot labels\n",
        "    data = np.loadtxt(data)\n",
        "    plt.plot(data)\n",
        "    plt.show()\n",
        "  def generate_images(self, file_path, label_path, gray=False):\n",
        "    # Takes the video file and generates images for each\n",
        "    # of it's frames. The time for each frame and the image path\n",
        "    # for the corresponding frame is stored in a csv\n",
        "\n",
        "    # Load the speeds\n",
        "    speeds = np.loadtxt(label_path)\n",
        "\n",
        "    # Video file\n",
        "    video_capture = cv2.VideoCapture(file_path)\n",
        "\n",
        "    # Check if number of labels is the same as number of frame\n",
        "    if len(speeds) == video_capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
        "      print(\"Labels are equal to number of frames\")\n",
        "    else:\n",
        "      print(\"Check if labels are equal to number of frames\")\n",
        "      return\n",
        "    \n",
        "    with open(\"processed.csv\", \"w+\") as file:\n",
        "      writer = csv.writer(file)\n",
        "      time_between_frames = 1 / FRAME_RATE\n",
        "      time_elapsed = 0\n",
        "\n",
        "      for idx, i in enumerate(speeds):\n",
        "        ret, frame = video_capture.read()\n",
        "        time_elapsed += time_between_frames\n",
        "        if gray == True:\n",
        "          frame = self.grayscale(frame)\n",
        "        if ret:\n",
        "          # cv2_imshow(frame)\n",
        "          image_path = OUTPUT_PATH + str(time_elapsed) + '.jpg'\n",
        "          cv2.imwrite(image_path, frame)\n",
        "          writer.writerow([image_path, time_elapsed, speeds[idx]])\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "      video_capture.release()\n",
        "      cv2.destroyAllWindows()\n",
        "\n",
        "  def shuffle_frame_pairs(self, dataframe, val_split=1):\n",
        "    \"\"\"Method that shuffles pairs of frames from the video.\n",
        "    Takes a dataframe as an argument, and returns a training\n",
        "    and validation dataframe. A custom method like this rather\n",
        "    than a traditional test, train split is used, as we need\n",
        "    pair of frames, later on to do optical flow\"\"\"\n",
        "    training_data = pd.DataFrame()\n",
        "    validation_data = pd.DataFrame()\n",
        "    df_len = dataframe.shape[0]\n",
        "    for i in range(df_len - 1):\n",
        "        idx1 = np.random.randint(df_len - 1)\n",
        "        idx2 = idx1 + 1\n",
        "        row1 = dataframe.iloc[[idx1]].reset_index()\n",
        "        row2 = dataframe.iloc[[idx2]].reset_index()\n",
        "        randInt = np.random.randint(9)\n",
        "        if 0 <= randInt <= val_split:\n",
        "            valid_frames = [validation_data, row1, row2]\n",
        "            validation_data = pd.concat(\n",
        "                valid_frames, axis=0, join='outer', ignore_index=False)\n",
        "        if randInt >= val_split + 1:\n",
        "            train_frames = [training_data, row1, row2]\n",
        "            training_data = pd.concat(\n",
        "                train_frames, axis=0, join='outer', ignore_index=False)\n",
        "\n",
        "    return training_data, validation_data\n",
        "\n",
        "  def adjust_brightness(self, image, factor, slice):\n",
        "    # Convert to hue, saturation, value model\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
        "    hsv[:, :, slice] = hsv[:, :, slice] * factor\n",
        "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "    return rgb\n",
        "\n",
        "  def crop_sky_and_dashboard(self, frame):\n",
        "      frame = frame[100:440, :-90]\n",
        "      image = cv2.resize(frame, (220, 66), interpolation=cv2.INTER_AREA)\n",
        "      return image\n",
        "\n",
        "  def optical_flow(self, im_c, im_n):\n",
        "      gray_c = self.grayscale(im_c)\n",
        "      gray_n = self.grayscale(im_n)\n",
        "      hsv = np.zeros_like(im_c)\n",
        "      hsv[:, :, 1] = cv2.cvtColor(im_n, cv2.COLOR_RGB2HSV)[:, :, 1]\n",
        "\n",
        "\n",
        "      flow = cv2.calcOpticalFlowFarneback(gray_c, gray_n,\n",
        "                                          flow_mat,\n",
        "                                          image_scale,\n",
        "                                          nb_images,\n",
        "                                          win_size,\n",
        "                                          nb_iterations,\n",
        "                                          deg_expansion,\n",
        "                                          STD,\n",
        "                                          0)\n",
        "\n",
        "      mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "      hsv[:, :, 0] = ang * (180 / np.pi / 2)\n",
        "      hsv[:, :, 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
        "      hsv = np.asarray(hsv, dtype=np.float32)\n",
        "      rgb_flow = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "      #cv2.imwrite(\"./flow.jpg\", rgb_flow)\n",
        "\n",
        "      return rgb_flow\n",
        "\n",
        "\n",
        "  def preprocess_image_valid_from_path(self, image_path, speed):\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      img = self.adjust_brightness(img, 0.2, 2)    \n",
        "      img = self.crop_sky_and_dashboard(img)\n",
        "      return img, speed\n",
        "\n",
        "\n",
        "  def preprocess_image_from_path(self, image_path, speed):\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      img = self.adjust_brightness(img, 0.2, 2)    \n",
        "      img = self.crop_sky_and_dashboard(img)\n",
        "      return img, speed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxos3XfSI95O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre = PreProcessor()\n",
        "pre.plot_training_speed(labels)\n",
        "pre.generate_images(train_video, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K_O3swh16k_",
        "colab_type": "code",
        "outputId": "d3e82162-7402-45dc-f5dc-c425ffcce595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxq2eEgC3HWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Conv2D, ELU, TimeDistributed, Flatten, Dropout, Lambda\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "IMG_SHAPE = (66, 220, 3)\n",
        "\n",
        "\n",
        "def speed_model():\n",
        "    inputs = Input(shape=IMG_SHAPE)\n",
        "    inputs1 = Lambda(lambda x: x/ 127.5 - 1, input_shape = IMG_SHAPE)(inputs)\n",
        "\n",
        "    conv1 = Conv2D(24, (5, 5), padding=\"valid\")(inputs1)\n",
        "    act1 = Activation(ELU())(conv1)\n",
        "    conv2 = Conv2D(36, (5, 5), strides=(2, 2), padding=\"valid\")(act1)\n",
        "    act2 = Activation(ELU())(conv2)\n",
        "    drop1 = Dropout(0.5)(act2)\n",
        "    conv3 = Conv2D(48, (5, 5), strides=(2, 2), padding=\"valid\")(drop1)\n",
        "    act3 = Activation(ELU())(conv3)\n",
        "    conv4 = Conv2D(64, (3, 3), strides=(1, 1), padding=\"valid\")(act3)\n",
        "    act4 = Activation(ELU())(conv4)\n",
        "    conv5 = Conv2D(64, (3, 3), padding=\"valid\")(act4)\n",
        "\n",
        "\n",
        "    flat1 = Flatten()(conv5)\n",
        "    act4 = Activation(ELU())(flat1)\n",
        "    dense1 = Dense(100)(act4)\n",
        "    act5 = Activation(ELU())(dense1)\n",
        "    dense2 = Dense(50)(act5)\n",
        "    act6 = Activation(ELU())(dense2)\n",
        "    dense4 = Dense(10)(act6)\n",
        "    act8 = Activation(ELU())(dense4)\n",
        "    output = Dense(1)(act8)\n",
        "\n",
        "    model = Model(inputs, output)\n",
        "    adam = Nadam()\n",
        "    model.compile(optimizer=adam, loss='mse')\n",
        "\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUOYnh8p3NSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training functions\n",
        "def generate_training_data(data, batch_size = 16):\n",
        "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
        "    label_batch = np.zeros((batch_size))\n",
        "    while True:\n",
        "        for i in range(batch_size):\n",
        "            idx = np.random.randint(1, len(data) - 1)\n",
        "            \n",
        "            row_now = data.iloc[[idx]].reset_index()\n",
        "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
        "            row_next = data.iloc[[idx + 1]].reset_index()\n",
        "            \n",
        "            time_now = row_now[1].values[0]\n",
        "            time_prev = row_prev[1].values[0]\n",
        "            time_next = row_next[1].values[0]\n",
        "            \n",
        "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
        "                row1 = row_prev\n",
        "                row2 = row_now\n",
        "                \n",
        "            elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
        "                row1 = row_now\n",
        "                row2 = row_next\n",
        "                \n",
        "            x1, y1 = pre.preprocess_image_from_path(row1[0].values[0],row1[2].values[0]) \n",
        "            x2, y2 = pre.preprocess_image_from_path(row2[0].values[0],row2[2].values[0])\n",
        "           \n",
        "            img_diff = pre.optical_flow(x1, x2)\n",
        "            y = np.mean([y1, y2])\n",
        "            \n",
        "            image_batch[i] = img_diff\n",
        "            label_batch[i] = y\n",
        "            \n",
        "        yield shuffle(image_batch, label_batch)\n",
        "\n",
        "\n",
        "def generate_validation_data(data):\n",
        "    while True:\n",
        "        for idx in range(1, len(data) - 1): \n",
        "            row_now = data.iloc[[idx]].reset_index()\n",
        "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
        "            row_next = data.iloc[[idx + 1]].reset_index()\n",
        "            \n",
        "            time_now = row_now[1].values[0]\n",
        "            time_prev = row_prev[1].values[0]\n",
        "            time_next = row_next[1].values[0]\n",
        "            \n",
        "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58:\n",
        "                row1 = row_prev\n",
        "                row2 = row_now\n",
        "                \n",
        "            elif time_next - time_now > 0 and 0.000001 < time_next - time_now < 0.58:\n",
        "                row1 = row_now\n",
        "                row2 = row_next\n",
        "\n",
        "            x1, y1 = pre.preprocess_image_valid_from_path(row1[0].values[0], row1[2].values[0])\n",
        "            x2, y2 = pre.preprocess_image_valid_from_path(row2[0].values[0], row2[2].values[0])\n",
        "            \n",
        "            img_diff = pre.optical_flow(x1, x2)\n",
        "            img_diff = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
        "            y = np.mean([y1, y2])\n",
        "            \n",
        "            speed = np.array([[y]])\n",
        "            yield img_diff, speed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoOFHhe-4h8T",
        "colab_type": "code",
        "outputId": "15a6240d-257f-4c44-8cf0-1edef1203044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "# training the model\n",
        "\n",
        "filepath = 'model-weights.h5'\n",
        "df = pd.read_csv(\"./processed.csv\", header = None)\n",
        "pre = PreProcessor()\n",
        "train, test = pre.shuffle_frame_pairs(df)\n",
        "size_test = len(test.index)\n",
        "size_train = len(train.index)\n",
        "#print(size_test)\n",
        "#print(size_train)\n",
        "dl_model = model.speed_model()\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', \n",
        "                          patience=2, \n",
        "                          verbose=1, \n",
        "                          min_delta = 0.23,\n",
        "                          mode='min',)\n",
        "modelCheckpoint = ModelCheckpoint(filepath, \n",
        "                                  monitor = 'val_loss', \n",
        "                                  save_best_only = True, \n",
        "                                  mode = 'min', \n",
        "                                  verbose = 1,\n",
        "                                  save_weights_only = True)\n",
        "callbacks_list = [modelCheckpoint, earlyStopping]\n",
        "train_generator = generate_training_data(train)\n",
        "test_generator = generate_validation_data(test)\n",
        "history = dl_model.fit_generator(\n",
        "        train_generator, \n",
        "        steps_per_epoch = 555,\n",
        "        epochs = 25,\n",
        "        callbacks = callbacks_list,\n",
        "        verbose = 1,\n",
        "        validation_data = test_generator,\n",
        "        validation_steps = size_test)\n",
        "\n",
        "print(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d374a853ca6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model-weights.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./processed.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle_frame_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./processed.csv' does not exist: b'./processed.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-fnSME-JSHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing all jpg images from folder\n",
        "\n",
        "import os\n",
        "for file in os.listdir(os.getcwd()): \n",
        "  if file.endswith('.jpg'):\n",
        "    os.remove(file) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIVGvMKEKOdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu-X830tku_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "9bc2a49e-a707-4416-f97b-f002db57aee8"
      },
      "source": [
        "# predict\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pre = PreProcessor()\n",
        "\n",
        "def predictions(data, model):\n",
        "    new_data = [] \n",
        "    for idx in range(1, len(data.index)-1):\n",
        "        row_now = data.iloc[[idx]].reset_index()\n",
        "        row_prev = data.iloc[[idx - 1]].reset_index()\n",
        "        row_next = data.iloc[[idx + 1]].reset_index()\n",
        "        \n",
        "        time_now = row_now[1].values[0]\n",
        "        time_prev = row_prev[1].values[0]\n",
        "        time_next = row_next[1].values[0]\n",
        "        \n",
        "        if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
        "            row1 = row_prev\n",
        "            row2 = row_now\n",
        "            \n",
        "        elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
        "            row1 = row_now\n",
        "            row2 = row_next\n",
        "            \n",
        "        x1, y1 = pre.preprocess_image_from_path(row1[0].values[0],row1[2].values[0]) \n",
        "        x2, y2 = pre.preprocess_image_from_path(row2[0].values[0],row2[2].values[0])\n",
        "       \n",
        "        img_diff = pre.optical_flow(x1, x2)\n",
        "        img_diff = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
        "        y = np.mean([y1, y2])\n",
        "        \n",
        "        prediction = model.predict(img_diff)\n",
        "        error = abs(prediction-y2)\n",
        "        new_data.append([prediction[0][0], y2, error[0][0], time_now, time_prev])\n",
        "    return pd.DataFrame(new_data)\n",
        "\n",
        "\n",
        "def get_pred_mse(preds):\n",
        "    df = pd.read_pickle(preds)\n",
        "    avg = np.mean(df[2].values**2)\n",
        "    return avg\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7b7bca1c943a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PreProcessor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTxpOcBsw9uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}